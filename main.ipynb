{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification and Semantic Segmentation of Blancked Resumes\n",
    "Goal : The ultimate objective is : \n",
    "    - to locate all company logos in a resume, find their associated company name, find their industry sector, etc, \n",
    "    - to locate and classify all icons that refers to a skill/hobby\n",
    "This test is a very wide problem. With the provided resources, you need to properly define what you will be focusing on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Introduction\n",
    "Given the fact that I don't have access to a GPU (working on Mac), I only defined the models, created some new datasets, and presented the main ideas I had regarding the subject and the ressources provided. On the report, I present the approach I had to the problem and to the datasets provided by Riminder. First, I created a deep model for binary classification, to detect wether a resume has a visual, logo or icon, then I defined a new dataset to augment the dataset, and to balance it. \n",
    "After that first model, I defined a second deep model, more specific to semantic segmentation, to detect exactly the location of these visuals - when found -, in each blank resume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Exploration of given data : \n",
    " The function __prepare_data()__ to prepare, extract information from the given datasets and returns two numpy arrays, one for the resumes and the other one for their labels . It takes as input the shape according to which the images will be extracted. \n",
    " I chose to use a (224, 224) since the majority of predefined deep learning architectures on Keras (VGG16, ResNet50..) use the same shape of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resumes with company :  234\n",
      "Number of resumes with icon :  55\n",
      "Number of resumes with both :  4\n",
      "Number of resumes with nothing :  1362\n"
     ]
    }
   ],
   "source": [
    "from toolbox import prepare_data\n",
    "input_size = 224\n",
    "x, y = prepare_data(input_size=input_size)\n",
    "\n",
    "print('Number of resumes with company : ' , sum(y=='has_company'))\n",
    "print('Number of resumes with icon : ' , sum(y=='has_icon'))\n",
    "print('Number of resumes with both : ' , sum(y=='has_both'))\n",
    "print('Number of resumes with nothing : ' , sum(y=='nothing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not enough images for each class..  \n",
    "We will transform the task to a binary classification : detecting wether a resume contains a visual (company logo, hobbies icon, both), or has none of these.  \n",
    "    - 1  : has no company, no icon logo, nothing  \n",
    "    - 0 : has either a company logo, an icon, or both   \n",
    "still a very unbalanced problem... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "y_binary = np.array([int(label =='nothing') for label in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUqf+F8Xu92atuGirAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18205b8d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reading and Preprocessing the images__ :  \n",
    "- Used ImageDataGenerator from keras preprocessing images package. \n",
    "- The advantage is generating generators, and batchs from a given directory or numpy array of images. \n",
    "- It allows many preprocessing tasks aswell, such as scaling, reshaping, and normalising : However, due to these tasks can be very greedy in terms computation force, so I only used a simple rescaling.\n",
    "- Also used a validation split of 0.1, to do some cross validation over the data. \n",
    "- The choice of the batch size depends on the computation power one has. 16 will allow me to run at least one epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        validation_split = 0.1,\n",
    "        )\n",
    "\n",
    "final_x = x\n",
    "final_y = y_binary\n",
    "\n",
    "train_generator = datagen.flow(final_x,\n",
    "                      to_categorical(final_y),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='training')\n",
    "\n",
    "validation_generator = datagen.flow(final_x,\n",
    "                      to_categorical(final_y),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Defining the Deep Classifier : __ \n",
    "- A VGG16 or ResNet50 Classifier : used the model predefined in Keras applications \n",
    "- I will use the ResNet50 for the rest, because the number of parameters is less important, while they both tend to have more or less the same scores on image classification tasks. \n",
    "\n",
    "__About Transfer Learning : __ I used transfer learning from pretrained models on the ImageNet challenge, by using the same weights to initialize my convolutional layers. Even though the task of natural image classification is completely different from the current task. It has been proven that the first convolution layers, can be very similar and thus, the transfer learning improves the convergence time and performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 55, 55, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 55, 55, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 55, 55, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4096)         411045888   flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4096)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            8194        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 434,641,794\n",
      "Trainable params: 434,588,674\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from toolbox import build_vgg_model, build_resnet_model\n",
    "\n",
    "clf_model = build_resnet_model(input_size=input_size,nb_classes=2)\n",
    "\n",
    "clf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact that data is unbalanced, I compute class weights then give it to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import Adam\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(final_y), \n",
    "                final_y)\n",
    "\n",
    "adam = Adam(lr = 0.0001)\n",
    "\n",
    "clf_model.compile(optimizer = adam,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_model.fit_generator(train_generator,\n",
    "                        class_weight=class_weights,\n",
    "                        shuffle = True,\n",
    "                        epochs = 10, \n",
    "                        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation : Generating new data set from existing blank resumes  \n",
    "- Resume are different from other natural images, where a rotation, scale change or other geometric transformations can be sufficient to augment data. The resume is an image where structure is important :  the header is usually for photos and candidate information, while the body contains the majority of text and the sides can contain visuals and logos.  \n",
    "- Thus, here is the approach I followed : I downloaded many icons from the provided websites, then created a function that takes as an argument all the empy resumes from the labeled data. I defined a variable __icons per resume__ which defines the number of icons I will add to each empy resume. Hence, all the empty resumes have icons now, and the advantage is that it allows me to have a mask for each one of these new images : a mask that i will use later for the semantic segmentation task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import glob\n",
    "from PIL import Image\n",
    "from toolbox import prepare_data\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "\n",
    "def prepare_data_seg(resumes, \n",
    "                     labels, \n",
    "                     resume_size = 224, \n",
    "                     icons_size = 24, \n",
    "                     icon_per_resume = 3 \n",
    "                     ):\n",
    "    \n",
    "    icons_sn_path  = '/Users/sayemothmane/Documents/MVA/Riminder/icons/145797-social-network-logo-collection/png'\n",
    "    icons_es_path = '/Users/sayemothmane/Documents/MVA/Riminder/icons/png'\n",
    "    icons = []\n",
    "    \n",
    "    for filename in glob.glob(icons_sn_path+'/*.png'): #assuming gif\n",
    "            im=Image.open(filename).resize((icons_size, icons_size))\n",
    "            im = np.array(im.convert(\"RGB\"))\n",
    "            im[im==0]=255\n",
    "            icons.append(im)  \n",
    "    for filename in glob.glob(icons_es_path+'/*.png'): #assuming gif\n",
    "            im=Image.open(filename).resize((icons_size, icons_size))\n",
    "            im = np.array(im.convert(\"RGB\"))\n",
    "            #im[im==0]=255\n",
    "            icons.append(im)\n",
    "        \n",
    "    icons = np.array(icons)\n",
    "\n",
    "\n",
    "    #x , y = prepare_data(resume_size)\n",
    "\n",
    "    empty_resumes = resumes[labels=='nothing', :, :,:]\n",
    "        \n",
    "    margin = 10\n",
    "    new_resumes = []\n",
    "    masks=[]\n",
    "    for resume in empty_resumes: \n",
    "        icons_list = random.sample(range(len(icons)), icon_per_resume)\n",
    "        for icon in icons_list : \n",
    "            mask  = np.zeros((resume_size, resume_size))\n",
    "            pos_w = random.randint(margin, resume_size-icons_size-margin)\n",
    "            pos_l = random.randint(margin, resume_size-icons_size-margin)\n",
    "            new_resume = np.array(resume, copy = True)\n",
    "            new_resume[pos_l:icons_size+pos_l, pos_w:icons_size+pos_w, :] = icons[icon, :, :]\n",
    "            mask[pos_l:icons_size+pos_l, pos_w:icons_size+pos_w] = 1\n",
    "            new_resumes.append(new_resume)\n",
    "            masks.append(mask)\n",
    "        \n",
    "    masks = np.array(masks)\n",
    "    new_resumes = np.array(new_resumes)\n",
    "    \n",
    "    return new_resumes, masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sayemothmane/anaconda3/lib/python3.6/site-packages/PIL/Image.py:888: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    }
   ],
   "source": [
    "icons_size = 24\n",
    "\n",
    "x_add, masks = prepare_data_seg(resumes=x, \n",
    "                                labels = y, \n",
    "                                resume_size = input_size, \n",
    "                                icons_size = icons_size, \n",
    "                                icon_per_resume = 2)\n",
    "\n",
    "final_x = np.concatenate((x,x_add), axis=0)\n",
    "final_y = np.concatenate((y_binary , np.zeros(x_add.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1821126320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "empty_resumes = x[y=='nothing', :, :,:]\n",
    "plt.imshow(empty_resumes[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrIcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1854f60ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_add[20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADx1JREFUeJzt3XGsnXV9x/H3ZwgloAaqQFipo5BqhstWsUESJnFjKpDF\nwhJdyaKdI6smkGjikhVNNrK/nBNNzDZMCcSyMJAJSP/ASW2MxmQgBWsBK1CwyqVNq2iADIO0fPfH\nee48v9t77eWec+4517xfyc15nt/5Ped8T57y4Xmec/J8U1VI0rTfGXcBkiaLoSCpYShIahgKkhqG\ngqSGoSCpMbJQSHJxkseS7EmyaVTvI2m4MorfKSQ5BngceDcwBTwAXFFVPxj6m0kaqlEdKZwH7Kmq\np6rqV8BtwLoRvZekIXrNiF53BfB03/oU8I65Jh+XZXU8J46oFEkAL/CLn1XVKUebN6pQyCxjzXlK\nko3ARoDjOYF35KIRlSIJ4Bv1lR/PZ96oTh+mgJV962cA+/onVNXmqlpbVWuPZdmIypD0ao0qFB4A\nVidZleQ4YD2wdUTvJWmIRnL6UFWHklwNfB04Bripqh4dxXtJGq5RXVOgqu4B7hnV60saDX/RKKlh\nKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGgsOhSQr\nk3wzye4kjyb5WDd+bZJnkuzs/i4dXrmSRm2Qm6wcAj5RVQ8leR3wYJJt3XOfr6rPDl6epMW24FCo\nqv3A/m75hSS76d3aXdISNpRrCknOBN4G3N8NXZ1kV5Kbkpw8jPeQtDgGDoUkrwXuAD5eVc8D1wNn\nA2voHUlcN8d2G5PsSLLjZV4atAxJQzJQKCQ5ll4g3FJVdwJU1YGqOlxVrwA30GshdwT7PkiTaZBv\nHwLcCOyuqs/1jZ/eN+1y4JGFlydpsQ3y7cMFwAeBh5Ps7MY+CVyRZA29NnF7gY8MVKGkRTXItw/f\nYfaekfZ6kJYwf9EoqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEgqWEoSGoYCpIahoKkhqEg\nqWEoSGoYCpIahoKkxiB3XgIgyV7gBeAwcKiq1iZZDnwZOJPe3Zc+UFW/GPS9JI3esI4U/qSq1lTV\n2m59E7C9qlYD27t1SUvAqE4f1gFbuuUtwGUjeh9JQzaMUCjg3iQPJtnYjZ3WdZCa7iR16syN7Psg\nTaaBrykAF1TVviSnAtuS/HA+G1XVZmAzwOuzvIZQh6QhGPhIoar2dY8HgbvoNX85MN3/oXs8OOj7\nSFocg3aIOrHrOE2SE4H30Gv+shXY0E3bANw9yPtIWjyDnj6cBtzVaxbFa4D/rKr/TvIAcHuSK4Gf\nAO8f8H0kLZKBQqGqngL+aJbxZ4GLBnltSePhLxolNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDU\nMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSY1h3I5NOsLX9+0c2Wu/93fXjOy1NUAoJHkLvd4O084C/gE4\nCfhb4Kfd+Cer6p4FVyhpUS04FKrqMWANQJJjgGfo3aPxw8Dnq+qzQ6lQ0qIa1jWFi4Anq+rHQ3o9\nSWMyrFBYD9zat351kl1Jbkpy8pDeQ9IiGDgUkhwHvA/4r27oeuBseqcW+4Hr5tjOZjDSBBrGkcIl\nwENVdQCgqg5U1eGqegW4gV4fiCNU1eaqWltVa49l2RDKkDQMwwiFK+g7dZhuAtO5nF4fCElLxEC/\nU0hyAvBu4CN9w59JsoZej8m9M56TNOEG7fvwIvCGGWMfHKgiSWPlz5wlNQwFSQ1DQVLDUJDUMBQk\nNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNbzFu0bC27AvXR4pSGrMKxS6G7AeTPJI39jy\nJNuSPNE9ntyNJ8kXkuzpbt567qiKlzR88z1S+BJw8YyxTcD2qloNbO/WoXfPxtXd30Z6N3KVtETM\nKxSq6tvAz2cMrwO2dMtbgMv6xm+unvuAk2bct1HSBBvkmsJpVbUfoHs8tRtfATzdN2+qG5O0BIzi\n24fMMlZHTEo20ju94HhOGEEZkhZikCOFA9OnBd3jwW58CljZN+8MYN/Mje37IE2mQUJhK7ChW94A\n3N03/qHuW4jzgeemTzMkTb55nT4kuRV4F/DGJFPAPwKfBm5PciXwE+D93fR7gEuBPcCL9LpQS1oi\n5hUKVXXFHE9dNMvcAq4apChJ4+MvGiU1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJ\nDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQ4aijM0QjmX5L8sGv2cleSk7rxM5P8MsnO7u+Loyxe0vDN\n50jhSxzZCGYb8AdV9YfA48A1fc89WVVrur+PDqdMSYvlqKEwWyOYqrq3qg51q/fRu2OzpN8Cw7im\n8DfA1/rWVyX5XpJvJXnnXBsl2ZhkR5IdL/PSEMqQNAwDNYNJ8ingEHBLN7QfeFNVPZvk7cBXk7y1\nqp6fuW1VbQY2A7w+y49oFiNpPBZ8pJBkA/DnwF91d3Cmql6qqme75QeBJ4E3D6NQSYtjQaGQ5GLg\n74H3VdWLfeOnJDmmWz6LXufpp4ZRqKTFcdTThzkawVwDLAO2JQG4r/um4ULgn5IcAg4DH62qmd2q\nJU2wo4bCHI1gbpxj7h3AHYMWJWl8/EWjpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIah\nIKlhKEhqGAqSGoaCpIahIKlhKEhqLLTvw7VJnunr73Bp33PXJNmT5LEk7x1V4ZJGY6F9HwA+39ff\n4R6AJOcA64G3dtv8+/Tt2SQtDQvq+/AbrANu627g+iNgD3DeAPVJWmSDXFO4umsbd1OSk7uxFcDT\nfXOmurEj2PdBmkwLDYXrgbOBNfR6PVzXjWeWubP2dKiqzVW1tqrWHsuyBZYhadgWFApVdaCqDlfV\nK8AN/PoUYQpY2Tf1DGDfYCVKWkwL7ftwet/q5cD0NxNbgfVJliVZRa/vw3cHK1HSYlpo34d3JVlD\n79RgL/ARgKp6NMntwA/otZO7qqoOj6Z0SaOQruPbWL0+y+sduWjcZUi/1b5RX3mwqtYebZ6/aJTU\nMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSY2F9n34\ncl/Ph71JdnbjZyb5Zd9zXxxl8ZKG76h3XqLX9+FfgZunB6rqL6eXk1wHPNc3/8mqWjOsAiUtrqOG\nQlV9O8mZsz2XJMAHgD8dblmSxmXQawrvBA5U1RN9Y6uSfC/Jt5K8c8DXl7TI5nP68JtcAdzat74f\neFNVPZvk7cBXk7y1qp6fuWGSjcBGgOM5YcAyJA3Lgo8UkrwG+Avgy9NjXbu4Z7vlB4EngTfPtr3N\nYKTJNMjpw58BP6yqqemBJKdMN5RNcha9vg9PDVaipMU0n68kbwX+B3hLkqkkV3ZPrac9dQC4ENiV\n5PvAV4CPVtV8m9NKmgDz+fbhijnG/3qWsTuAOwYvS9K4+ItGSQ1DQVLDUJDUMBQkNQwFSQ1DQVLD\nUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUmM9NVlYm+WaS3UkeTfKxbnx5km1Jnuge\nT+7Gk+QLSfYk2ZXk3FF/CEnDM58jhUPAJ6rq94HzgauSnANsArZX1Wpge7cOcAm927Ctpndj1uuH\nXrWkkTlqKFTV/qp6qFt+AdgNrADWAVu6aVuAy7rldcDN1XMfcFKS04deuaSReFXXFLqmMG8D7gdO\nq6r90AsO4NRu2grg6b7NproxSUvAvEMhyWvp3X/x47P1ceifOstYzfJ6G5PsSLLjZV6abxmSRmxe\noZDkWHqBcEtV3dkNH5g+LegeD3bjU8DKvs3PAPbNfE37PkiTaT7fPgS4EdhdVZ/re2orsKFb3gDc\n3Tf+oe5biPOB56ZPMyRNvvm0jbsA+CDw8HTLeeCTwKeB27s+ED8B3t89dw9wKbAHeBH48FArljRS\n8+n78B1mv04AcNEs8wu4asC6JI2Jv2iU1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAU\nJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDXSu3vamItIfgr8L/CzcdcygDeytOuHpf8Z\nlnr9MNrP8HtVdcrRJk1EKAAk2VFVa8ddx0It9fph6X+GpV4/TMZn8PRBUsNQkNSYpFDYPO4CBrTU\n64el/xmWev0wAZ9hYq4pSJoMk3SkIGkCjD0Uklyc5LEke5JsGnc985Vkb5KHk+xMsqMbW55kW5In\nuseTx11nvyQ3JTmY5JG+sVlr7nqBfqHbL7uSnDu+yv+/1tnqvzbJM91+2Jnk0r7nrunqfyzJe8dT\n9a8lWZnkm0l2J3k0yce68cnaB1U1tj/gGOBJ4CzgOOD7wDnjrOlV1L4XeOOMsc8Am7rlTcA/j7vO\nGfVdCJwLPHK0mun1A/0avZaB5wP3T2j91wJ/N8vcc7p/T8uAVd2/s2PGXP/pwLnd8uuAx7s6J2of\njPtI4TxgT1U9VVW/Am4D1o25pkGsA7Z0y1uAy8ZYyxGq6tvAz2cMz1XzOuDm6rkPOCnJ6YtT6ezm\nqH8u64DbquqlqvoRvYbH542suHmoqv1V9VC3/AKwG1jBhO2DcYfCCuDpvvWpbmwpKODeJA8m2diN\nnVZV+6H3DwA4dWzVzd9cNS+lfXN1d3h9U98p20TXn+RM4G3A/UzYPhh3KMzWzXqpfB1yQVWdC1wC\nXJXkwnEXNGRLZd9cD5wNrAH2A9d14xNbf5LXAncAH6+q53/T1FnGRv4Zxh0KU8DKvvUzgH1jquVV\nqap93eNB4C56h6YHpg/vuseD46tw3uaqeUnsm6o6UFWHq+oV4AZ+fYowkfUnOZZeINxSVXd2wxO1\nD8YdCg8Aq5OsSnIcsB7YOuaajirJiUleN70MvAd4hF7tG7ppG4C7x1PhqzJXzVuBD3VXwM8Hnps+\nxJ0kM86xL6e3H6BX//oky5KsAlYD313s+volCXAjsLuqPtf31GTtg3Feje27wvo4vavDnxp3PfOs\n+Sx6V7a/Dzw6XTfwBmA78ET3uHzctc6o+1Z6h9gv0/u/0JVz1Uzv0PXfuv3yMLB2Quv/j66+XfT+\nIzq9b/6nuvofAy6ZgPr/mN7h/y5gZ/d36aTtA3/RKKkx7tMHSRPGUJDUMBQkNQwFSQ1DQVLDUJDU\nMBQkNQwFSY3/A7szTCFVJA77AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18550445f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(masks[20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the augmented dataset for the classification task :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        validation_split = 0.1,\n",
    "        )\n",
    "\n",
    "final_x = np.concatenate((x,x_add), axis=0)\n",
    "final_y = np.concatenate((y_binary , np.zeros(x_add.shape[0])))\n",
    "\n",
    "train_generator = datagen.flow(final_x,\n",
    "                      to_categorical(final_y),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='training')\n",
    "\n",
    "validation_generator = datagen.flow(final_x,\n",
    "                      to_categorical(final_y),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='validation')\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(final_y), \n",
    "                final_y)\n",
    "\n",
    "\n",
    "#============ Defining first binary classification model ==================\n",
    "\n",
    "clf_model = build_vgg_model(input_size=input_size,nb_classes=2)\n",
    "\n",
    "#clf_model = build_resnet_model(input_size=input_size,nb_classes=2)\n",
    "\n",
    "adam = Adam(lr = 0.0001)\n",
    "\n",
    "clf_model.compile(optimizer = adam,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "clf_model.fit_generator(train_generator,\n",
    "                        class_weight=class_weights,\n",
    "                        shuffle = True,\n",
    "                        epochs = 10, \n",
    "                        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Semantic Segmentation : \n",
    "- The goal of this part is to define localize the visual (logo, icons..) within each resume. The architecture of models I chose to use, is the known Fully Convolutional Networks. \n",
    "- I implemented the FCN_VGG_32. Being constrained by time I wasn't able to look for some pretrained models, on segmentation datasets such as Pascal VOC 2011, specially for Keras... Would have been interesting to see the effect of transfer learning on such task aswell.\n",
    "- The dataset I use is the one I created before. The masks of the 'new_resumes' are know since I placed them on empty resumes. I use also some empty resumes, with empy masks.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sayemothmane/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from BilinearUpSampling import *\n",
    "\n",
    "def build_fcn_vgg_32(input_shape = (224, 224, 3), nb_classes = 2):\n",
    "    \n",
    "    vgg_model = VGG16(\n",
    "            include_top = False,\n",
    "            weights='imagenet',\n",
    "            input_shape = input_shape\n",
    "            )\n",
    "        \n",
    "    vgg_output = Conv2D(4096,\n",
    "                        (7,7), \n",
    "                       activation = 'relu', \n",
    "                       padding = 'same')(vgg_model.output)\n",
    "    vgg_output = Dropout(0.5)(vgg_output)\n",
    " \n",
    "    vgg_output = Conv2D(4096,\n",
    "                        (7,7),\n",
    "                       activation = 'relu', \n",
    "                       padding = 'same')(vgg_output)\n",
    "    vgg_output = Dropout(0.5)(vgg_output)\n",
    "\n",
    "    vgg_output = Conv2D(nb_classes,\n",
    "                        (1,1),\n",
    "                        activation = 'linear',\n",
    "                        padding='valid', \n",
    "                        strides=(1, 1))(vgg_output)\n",
    "    \n",
    "    vgg_output = BilinearUpSampling2D(size=(32, 32))(vgg_output)\n",
    "    \n",
    "    final_model=Model(vgg_model.input,vgg_output)\n",
    "    \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = build_fcn_vgg_32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 4096)        822087680 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 2)           8194      \n",
      "_________________________________________________________________\n",
      "bilinear_up_sampling2d_1 (Bi (None, 224, 224, 2)       0         \n",
      "=================================================================\n",
      "Total params: 939,575,106\n",
      "Trainable params: 939,575,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        validation_split = 0.1,\n",
    "        )\n",
    "\n",
    "seg_train_generator = datagen.flow(x_add,\n",
    "                      to_categorical(masks),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='training')\n",
    "\n",
    "seg_validation_generator = datagen.flow(x_add,\n",
    "                      to_categorical(masks),\n",
    "                      batch_size = batch_size, \n",
    "                      shuffle = True, \n",
    "                      subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr = 0.0001)\n",
    "seg_model.compile(optimizer = adam,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_model.fit_generator(train_generator,\n",
    "                        class_weight=class_weights,\n",
    "                        shuffle = True,\n",
    "                        epochs = 10, \n",
    "                        validation_data=validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
